# 하드웨어와 운영체제
하드웨어의 엄청난 발전(무어의 법칙)으로 인해 소프트웨어가 복잡해지고 거대해졌고 런타임에 많은 것을 자동으로 처리하도록 설계된 자바는 많은 혜택을 받았음

CPU의 성능이 발전하면서 클럭수를 증가시켜서 처리 속도 상승을 얻을 수 있었다

→ 그러나 I/O성능의 발전이 이를 따라오지 못해 프로세스 코어의 메모리 수요를 메인 메모리가 따라가질 못하는 이슈 발생 (처리속도가 상승해도 데이터가 안오니 의미가 없다..!)

→ 그래서 CPU안에 있는 메인 메모리라고 할 수 있는 캐시가 등장

- 레지스터보다는 느리지만 메인 메모리보다는 훨씬 빠름
- 엑세스 빈도가 높을수록 코어와 더 가까지 배치, L1, L2로 가까운 순서대로 명명
- 보통 각 실행코어에 전용 프라이빗 캐시 L1,L2를 두고 모든 코어가 공유하는 L3캐시를 둠
- 메인 메모리보다 L1 캐시가 10배 이상 빠름 (표 참고)

→ 데이터 엑세스 시간 차이가 엄청 크므로 최신 CPU는 캐시 아키텍쳐에 적극적으로 투자

- CPU코어마다 L1,L2 캐시가 있고 모든 코어가 공유하는 L3 캐시
- 메인 메모리는 **노스브리지(Northbridge)** 컴포넌트 칩셋을 사용하여 엑세스 시간이 줄어듦.
    - 노스브릿지는 CPU내부에 존재하는 컨트롤러 칩셋으로, PCI-E (그래픽 카드), 메모리, CPU, 사우스브릿지간의 통신 허브임. - 메모리 컨트롤러 허브
    - 옛날엔 메인보드에 존재했지만 CPU내부에 있는게 더 빨라서 통합되었음
    - 사우스브릿지는 USB, Audio, SATA와 같은 외부기기들의 I/O를 연결

→ 캐시가 여러개여서 생기는 무결성 이슈가 있고 이를 해결하기 위해 **캐시 일관성 프로토콜**을 정의

- 병렬처리 환경에서는 문제 발생..
- 프로세서의 가장 저수준에 있는 MESI 프로토콜 (캐시라인 상태를 4가지로 정의)
    - **Modified(수정)** : 데이터가 수정된 상태 (메인 메모리에 써야함)
    - **Exclusive(베타)** : 해당 캐시에서만 존재하고 메인 메인 내용과 동일
    - **Shared(공유)** : 둘 이상의 캐시에 데이터가 들어있고 메모리 내용과 동일
    - **Invalid(무효)** : 다른 프로세스가 데이터를 수정하여 무효된 상태
- 한 프로세서가 수정이나 베타 상태로 바뀌면 해당 메모리영역이 저장된 다른 프로세서의 캐시의 상태는 모두 강제로 무효 상태가 됨.
    - 프로세서가 상태를 바꾸겠따는 의사를 브로드캐스팅하여 이를 다른 프로세서가 알아챔.
    - 상태 변이 참고
- 처음에는 캐시 연산이 나오면 바로 메모리에 기록
    - 동시기록, write-through라고 함
- 대역폭을 너무 많이 소모해서 후 기록(write-back) 방식 채택
    - 블록을 교체해도 프로세서가 더티 캐시 블록만 메모리에 기록.
- 이론적으로 가능한 최대전송률(burst rate)은 3개에 따라 결정됨.
    - 메모리 클록 주파수
    - 메모리 버스 폭(보통 64bits)
    - 인터페이스 개수(보통 2개-DDR)
- DDR(Double Data Rate) RAM은 클록 신호 양단에서 통신해서 전송률이 2배

**메모리 엑세스하는게 시간이 제일 많이 소모**하므로 코드상의 직감만으로 JVM 내부에서 처리 속도를 섣부르게 판단하지 말 것!!

```java
int[] testData = new int[2 * 1024 * 1024]; // 8MB
for(int i = 0; i < 15_000; i++){
	for(int j = 0; j < testData.length; j ++){
		testData[j]++;
	}
	for(int j = 0; j < testData.length; j+=16){
		testData[j]++;
	}
}
```

- 위 코드는 아래 for문이 16배 더 빠를 것 같지만 그렇지 않음!
- 메모리 엑세스 속도가 제일 느리기 때문
- 둘다 접근하는 메모리는 영역은 같아서 메모리에서 캐시로 가지고 오는 시간이 압도적이라 16배 적은 CPU 연산을 미미하게 만듦
- 요즘 CPU는 메모리에 대한 stride 엑세스 패턴을 감지해서 미리 읽어오는 하드웨어 프리패처 장치가 있음

### 최신 프로세스 특성

메모리 캐시는 점점 증가한 트랜지스터를 가장 확실하게 활용하는 분야이지만 다른 기술도 등장함

1. 변환 색인 버퍼 (Translation Lookaside Buffer, TLB)
    - 가상 메모리 주소를 물리 메모리 주소로 매핑하는 페이지 테이블의 캐시
    - 가상 주소를 참고해 물리 주소에 엑세스하는 속도가 매우 빨라짐
    - TLB가 없으면 L1캐시에 페이지 테이블이 있어도 가상주소 룩업에 16사이클이나 걸려서 성능 면에서 필수
2. **분기 예측**과 추측 실행
    - 프로세서가 조건 분기하는 기준값을 예측해서 다음값들을 실행
    - 프로세서는 트랜지스터를 아낌없이 사용해 발생 가능성이 가장 큰 브랜치를 미리 결정하는 휴리스틱 형성
    - 추측한 결과를 바탕으로 그 뒤의 파이프라인을 채우고 작업 진행
        - 운좋게 맞아 떨어지면 그대로 사용
        - 틀리면 부분적으로 실행한 명령을 모두 폐기하고 다시 채움
    - 2018년 이걸 악용할 수 있다는 취약점이 화제가 되었었음
3. 하드웨어 메모리 모델
    - 어떻게 하면 서로 다른 여러 CPU가 일관되게 동일한 메모리 주소를 엑세스할 수 있을까? 라는 문제에 대한 해답
    - JIT컴파일러인 javac과 CPU는 코드 실행순서를 바꿀 수 있음.
        - 실행 순서를 바꿔도 실행 결과에 영향을 미치지 않는다는 건에 한해서만 가능
        - 이러한 순서 바꾸기는 CPU에 따라 조금씩 차이 있음
    - JMM은 프로세서 타입별로 메모리 액세스하는 법이 조금씩 차이가 있어서 명시적으로 약한 모델(메모리 정렬에 관한 용어)로 설계되었음.
        - 락과 volatile을 정확히 알고 사용해야함

## 운영체제

여러 실행 프로세서가 공유하는 리소스 액세스를 관장하는 일

모든 리소스는 한정되어 있고 프로세서는 리소스를 많이 차지하려고 하기 때문에 리소스 양을 보고 골고루 나누어주는 중앙 시스템

한정된 리소스 중에서도 메모리와 CPU시간은 가장 중요하다

메모리 관리 유닛(Memory Management Unit, MMU)

- 가상 주소(virtual addressing) 방식, 페이지 테이블
- 메모리 액세스 제어의 핵심
- 한 프로세서가 소유한 메모리 영역을 다른 프로세서가 함부로 훼손하지 못하게 함

TLB는 물리 메모리 주소 룩업 시간을 줄이는 하드웨어 기능

- 버퍼를 사용하면 소프트웨어가 메모리에 액세스 하는 성능이 향상되지만,
- MMU는 개발자가 내부를 파악하기엔 너무 저수준이라 OS 액세스 스케줄러를 살펴봐야함

### 스케줄러

CPU 액세스를 통제

- 실행 큐를 이용함

인터럽트에 응답하고 CPU코어 액세스를 관리

자바 스레드 수명주기

- 스레드 - **(실행, sleep, wait, i/o, 죽음)**

스레드를 단일 코어로 분주히 나름

- 스레드별로 할당 시간 부여(실행시간)
- 할당 시간 끝 무렵에 실행 큐로 다시 되돌려서 다시 실행될때 까지 대기
- 스레드가 자신에게 할당된 시간을 포기하려면 sleep()이나 wait()로 대기조건 명시
- I/O나 소프트웨어 락에 걸려 블로킹될수도 있음

OS특성상 CPU에서 코드가 실행되지 않는 시간을 유발함. (할당하고 실행큐에서 대기하고 다시 실행될때까지 암것도 못함...)

- **스케줄링 오버헤드**가 측정 결과에 노이즈를 끼게함
- 스케줄러를 모니터링하려면 스케줄링 과정에서 발생시킨 오버헤드를 관측해야함.

운영체제에 따라서 시간을 측정하는 방식, 오버헤드가 발생하는 정도가 다 달라서 이를 고려해야함.

### 타이밍(시간측정)

POSIX(Portable Operating System Interface)라는 업계 표준이 있지만 OS는 저마다 다르게 동작

JAVA의 `os::javaTimeMillis()`는 OS를 네이티브 단에서 직접 호출함

- 유닉스, 리눅스와 윈도우의 구현이 완전 다름. (리눅스 - timeVal, 윈도우 - FileTIME)
- 운영체제 마다 시간 측정값이 달라질 수 있음.

### 컨텍스트 스위치

OS가 현재 실행중인 스레드/태스크를 없애고 대기중인 다른 스레드/태스크로 교체하는 프로세스

스레드 실행 명령과 스택 상태를 교체하는 모든 일과 연관

- 유저 스레드 사이에서 발생
- 유저 모드 → 커널 모드로 바뀌면서 발생(모드 교환)
    - 타임 슬라이스, 선취(OS가 멀티태스킹을 구현하기 위해 프로세스의 동의없이 임의로 인터럽트를 걸고 나중에 다시 프로세스를 재개)

**비싼 작업이다.**

- 특히 유저→커널은 서로 공유하는 메모리 영역이 거의 없어서 캐시를 강제로 비워야함
    - 이 작업은 **TLB를 비롯한 다른 캐시도 무효화됨**
    - 시스템 콜 반환시 다시 채워야해서 다시 유저모드로 돌아갈때도 똑같은 현상 발생
    - 이를 해결하기 위해 리눅스는 vDSO(가상 동적 공유 객체)장치 제공 (커널 프리빌리지나 부수 효과 - side effect가 일어나지 않는 시스템 콜에 대해 커널 전환을 하지않고 vDSO에 매핑하여 사용)

## 단순 시스템 모델

**자바 애플리케이션이 실행되는 모델**을 단순하게 정의하자면

1. 애플리케이션이 실행되는 하드웨어와 OS
2. 애플리케이션이 실행되는 JVM/컨테이너
3. 애플리케이션이 코드 자체
4. 애플리케이션이 호출하는 외부 시스템
5. 애플리케이션으로 유입되는 트래픽

이들 중 누구라도 성능 문제를 일으킬 수 있다.

- 시스템의 특정 부위를 좁혀가거나 격리하는 방법으로 누가 진범인지 밝혀낼 수 있음.

## 기본 감지 전략

첫 단추는 어느 리소스가 한계에 다다랐는지 밝히는 일

부족한 리소스를 모르면 성능 지표를 보고 필요한 리소스 튜닝을 할 수 없음.

### CPU 사용률

애플리케이션 성능을 나타내는 핵심 지표

CPU 사이클은 애플리케이션이 가장 많이 요구하는 리소스

- CPU의 효율적 사용을 성능 향상을 지름길
- 부하가 집중되는 도중에는 사용률이 가능한 한 100%에 가까워야함

성능 엔지니어는 기본 툴 두가지

- **vmstat, iostat**정도는 쓸 줄 알아야함.
- 각각 현재 가상 메모리 및 I/O 서브시스템 상태에 관한 유용한 데이터를 제공
    - 전체 호스트 수준의 수치만 나오지면 간략히 파악 가능
    - 83쪽 페이지 참고(vmstat 읽는법)

**컨텍스트 스위치**는 어떠한 경우든 CPU리소스를 낭비

- 튜닝이 잘 된프로그램은 리소스를 100% 사용하려고함
- **반대로 말하면 CPU 사용률이 100%에 근접하지 않으면 왜그럴까?를 따져봐야함.**
    - 유저 공간에서 CPU사용률이 100%근처도 못갔는데 어떤 프로세스에서 컨텍스트 교환 비율이 높으면 I/O에서 블로킹이 일어났거나, 스레드 락 경합 상황이 벌어졌을 가능성이 큼.
- vmstat만으로는 I/O문제는 파악 가능하지만 여러 경우의 수를 알긴 어려워 다른 툴 필요
    - **스레드 프로파일러, VisualVM 등**

### 가비지 수집

핫스팟 JVM은 시작시 메모리를 유저 공간에 할당/관리함

메모리를 할당하느라 시스템 콜을 할 필요가 없음

- 즉, 가비지 수집을 하려고 커널교환을 할 일이 거의 없음.
- 따라서 GC자체는 유저 공간의 CPU 사이클을 소비하되 커널 공간의 사용률에는 영향을 미치지 않는 활동임
- 반면, JVM프로세스가 유저 공간에서 CPU를 100% 가깝게 사용하고 있으면 GC를 의심해야함.
    - vmstat같은거에서 모든 사이클이 유저공간에서 소비되고 있으면
        - JVM일까? 유저 코드일까? 생각해야함
        - 대부분 GC서브시스템 탓
        - 따라서 로그 확인해야함
- JVM에서 GC로깅은 분석하기 좋고 로깅도 쉬워서 꼭 남기자 (특히 운영환경에선 더욱 더)

### 입출력

파일 I/O는 다른 OS처럼 분명하게 추상화되어있지 않음

가상 메모리라는 격리 장치가 있지만, 애플리케이션 개발자가 적절히 추상화하지 못함

다행히 자바 프로그램은 대부분 단순한 I/O만 처리

I/O를 많이 쓰는 프로세스를 활발하게 모니터링해야함

- 애플리케이션에서 I/O가 어떻게 일어나는지 인지하는 것만으로도 충분함(iostat)

커널 바이패스 I/O

- 커널 대신 하드웨어로부터 유저가 접근 가능한 영역으로 데이터를 매핑하는 전용 하드웨어/소프트웨어 사용
- 그러면 커널 공간과 유저 공간에 둘다 복사되는 이중 복사 막을 수 있음
- 자바는 이런 기능 없어서 커스텀, 네이티브 라이브러리 사용해야함
- 그치만 초고성능 I/O가 필요한 시스템에서는 구현 필수

### 기계공감

기계 공감이라는 것은 **성능을 조금이라도 향상시키려면 하드웨어를 폭넓게 이해하고 공감할 수 있는 능력이 무엇보다 중요**하다는 생각

자바/JVM을 효과적으로 활용하려면 하드웨어와 어떤 상호작용하는지, JVM은 무엇인지 이해해야함.

캐시라인 충돌과 같이 어떠한 성능 급락을 해결하려면, 먼저 이런 일이 발생할 수 있음을 이해하고 있어야지만 해결 방법을 찾을 수 있음.

- 자바 객체는 필드 배치가 고정되지 않기 때문에 캐시 라인을 공유한 변수를 쉽게 찾을 수 있음.

## 가상화

이미 실행 중인 다른 OS 위에서 OS사본을 하나의 프로세스로 실행시키는 모양

가상화의 특징 3가지

- 가상화 OS에서 실행하는 프로그램은 베어메탈에서 실행할 때와 동일하게 작동해야 한다.
- 하이퍼바이저는 모든 하드웨어 리소스 액세스를 조정해야 한다.
- 가상화 오버헤드는 가급적 작아야 하며, 실행 시간의 상당 부분을 차지해선 안 된다.

가상화 시스템에서는 게스트 OS가 하드웨어에 직접 액세스 할 수 없음.

- 특권(프리빌리지드)명령어를 unprevileged명령어로 고쳐쓰고,
- 지나친 캐시 플러시가 일어나지 않도록 OS커널의 자료구조를 섀도(shadow)함
    
    ⇒ 따라서 **가상 환경 내에서 프로그램을 실행하는 것은 성능 분석 및 튜닝을 한층 더 복잡하게 만듦!!**
    

## JVM과 운영체제

JVM은 **자바 코드에 공용 인터페이스를 제공**하여 **OS독립적인 실행 환경**을 제공한다.

하지만 스레드 스케줄링 또는 시스템 클록에서 시간 정보를 얻는 작업 같은 아주 기본적인 서비스들 조차 하부 OS에 반드시 액세스 해야함.

- 이런 기능은 native 키워드를 붙인 네이티브 메서드로 구현함
- C언어로 작성, 자바 메서드처럼 액세스 가능함
- 이 작업을 대행하는 공통 인터페이스를 자바 네이티브 인터페이스(JNI)라고 한다.
    - java.lang.Object에 선언되어있는 네이티브 메서드
    
    ```java
    public final native Class<?> getClass();
    public native int hashCode();
    protected native Object clone() throws ConeNotSupportedExcpetion;
    public final native void notify();
    ```
    

C++ `os::javaTimeMillis()`함수는 자바 정적 메서드 `System.curruentTimeMillis()`에 구현된 로직을 처리

- 실제 코드는 C++로 작성되었지만 자바에서 C 코드 ‘브리지bridge’를 통해 액세스 할 수 있음.
- 핫스팟에서 이 코드는 실제로 어떻게 호출될까?
    1. `System.currentTimeMillis()`는 `JVM_CurrentTimeMillis()`라는 JVM 엔트리 포인트 메서드에 매핑됨.
    2. `.java/lang/System.c` 파일에 포함된 JNI (`Java_java_lang_System_registerNatives()`)에 매핑관계가 설정되어 있음.
    3. `JVM_CurrentTimeMillis()`는 VM 진입점에 해당하는 메서드를 호출
        - C 함수지만 C 호출 관례에 따라 익스포트된 C++함수
    4. OpenJDK 매크로 2개로 감싼 `os::javaTimeMillis()`를 호출하는 구조
        - os 이름공간에 정의되어 있고 당연히 OS에 따라 의존
    5. OpenJDK를 뒤져보면 OS별 서브디렉터리 어딘가에 소스코드가 있음(OS에 맞는….)
        - 그니까 **OS의존적인 서비스들은 이걸 매핑하는 코드가 OpenJDK내부에 있음!!**